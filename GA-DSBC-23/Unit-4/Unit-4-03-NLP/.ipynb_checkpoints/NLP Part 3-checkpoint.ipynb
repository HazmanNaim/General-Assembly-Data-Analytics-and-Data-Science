{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b44b276",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP Part 3: Spam Classification \n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Implement `CountVectorizer` and `TfidfVectorizer` in a spam classification model.\n",
    "- Use `GridSearchCV` and `Pipeline` with `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ef5e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (D:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultinomialNB\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, plot_confusion_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer, TfidfVectorizer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (D:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494fe7d",
   "metadata": {},
   "source": [
    "# Spam Classification Model\n",
    "\n",
    "One common application of NLP is predicting \"spam\" vs. \"ham,\" or \"spam\" vs. \"not spam.\"\n",
    "\n",
    "Can we predict real vs. promotional texts just based on what is written?\n",
    "\n",
    "> This data set was taken from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) and consists of SMS messages that have been labeled as either \"spam\" or \"ham\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c5dc2",
   "metadata": {},
   "source": [
    "# Reminder of the Data Science Process\n",
    "1. Define problem.\n",
    "2. Gather data.\n",
    "3. Explore data.\n",
    "    - Yes, we can still do EDA with text data!\n",
    "    - We also have to pre-process our text data to prepare it for modeling.\n",
    "4. Model with data.\n",
    "5. Evaluate model.\n",
    "6. Answer problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data.\n",
    "spam = pd.read_csv('data/SMSSpamCollection',\n",
    "                 sep='\\t',\n",
    "                 names=['label', 'message'])\n",
    "\n",
    "# Check out first five rows.\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fae252",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7bb5d",
   "metadata": {},
   "source": [
    "## Let's get our data\n",
    "---\n",
    "\n",
    "Convert ham/spam into binary labels. We are interested in identifying spam, so set spam as the event of interest (value of 1) \n",
    "- 0 for ham\n",
    "- 1 for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ea9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam['label'] = spam['label'].map({'ham': 0, 'spam': 1})\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b67c2d",
   "metadata": {},
   "source": [
    "Let's set up our data for modeling:\n",
    "- `X` will be the `message` column. **NOTE**: `CountVectorizer` requires a vector, so make sure you set `X` to be a `pandas` Series, **not** a DataFrame.\n",
    "- `y` will be the `label` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam['message']\n",
    "y = spam['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b77f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what we need to check in a classification problem - how many of each event\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc4dc8",
   "metadata": {},
   "source": [
    "## `CountVectorizer`\n",
    "---\n",
    "\n",
    "Now we can use the `CountVectorizer` to transform the training data to a Term-Document Matrix, before applying a classification model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer with the default hyperparameters.\n",
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ff8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on our corpus (find all the tokens)\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba74ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus to a matrix by calculating the occurrences of each token\n",
    "X_train_tdm = cvec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee07c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train is now a term-document matrix\n",
    "X_train_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62322d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few of the features\n",
    "cvec.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training data to dataframe\n",
    "X_train_df = pd.DataFrame(X_train_tdm.todense(), \n",
    "                          columns=cvec.get_feature_names())\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top occuring words\n",
    "X_train_df.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6352c3",
   "metadata": {},
   "source": [
    "## Modelling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06916d9",
   "metadata": {},
   "source": [
    "At this point, we could fit a model (like a logistic regression model or $k$-nearest neighbors model) using our transformed data, or continue doing more pre-processing such as tokenizing, lemmatizing or stemming.\n",
    "\n",
    "Let's try to fit a classification model first.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d61bbd",
   "metadata": {},
   "source": [
    "## Naïve Bayes\n",
    "\n",
    "We will try to use a Naïve Bayes classifier. Naïve Bayes relies on [Bayes theorem](https://www.mathsisfun.com/data/bayes-theorem.html), which is based on conditional probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0f6fc",
   "metadata": {},
   "source": [
    "If we know $P(B|A)$, Bayes theorem allows us to calculate the probability of $P(A|B)$ by relating the probability of $P(A|B)$ to $P(B|A)$. \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Bayes' Theorem: } P(A|B) &=& \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "- Let $A$ be that a message is spam.\n",
    "- Let $B$ represent the words used in the message.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Bayes' Theorem: } P(A|B) &=& \\frac{P(B|A)P(A)}{P(B)} \\\\\n",
    "\\Rightarrow P(\\text{message is spam}|\\text{words in message}) &=& \\frac{P(\\text{words in message}|\\text{message is spam})P(\\text{message is spam})}{P(\\text{words in message})}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "We want to calculate the probability that a post is spam **given** the words that are in the message! Our model can learn this from the training data.\n",
    "\n",
    "**Naïve Bayes** makes the assumption that all features are independent of one another (this is why it is called *naïve*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6cdbe",
   "metadata": {},
   "source": [
    "<details><summary>Why is this assumption not realistic with our data?</summary>\n",
    "    \n",
    "Text data is never independent! Words have different context when they appear together.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002651",
   "metadata": {},
   "source": [
    "Despite this assumption not being realistic with NLP data, we still use Naïve Bayes pretty frequently.\n",
    "- It's a very fast modeling algorithm (which is great especially when we have lots of features and/or lots of data!).\n",
    "- It is often an excellent classifier, outperforming more complicated models.\n",
    "\n",
    "There are three common types of Naive Bayes models: Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes.\n",
    "- How do we pick which of the three models to use? It depends on our $X$ variable.\n",
    "    - [Bernoulli Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB): when we have predictor variables with binary 0/1 values\n",
    "    - [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB): when our predictor variables are positive integers.\n",
    "    - [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB): when our features are Normally distributed.\n",
    "    \n",
    "Let's try to fit the `MultinomialNB` classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "mb = MultinomialNB()\n",
    "\n",
    "# fit on the transformed X_train data\n",
    "mb.fit(X_train_tdm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score on training data\n",
    "mb.score(X_train_tdm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dde266",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "As always, we have to evaluate the model on our test data. But remember we have to transform the test data into a term document matrix as well before it can be scored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_test by calculating the occurrences of each token already defined by X_train\n",
    "X_test_tdm = cvec.transform(X_test)\n",
    "X_test_tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb91231",
   "metadata": {},
   "source": [
    "## Baseline accuracy\n",
    "\n",
    "We need to calculate baseline accuracy in order to tell if our model is better than null model (predicting the plurality class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bb874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1eb39",
   "metadata": {},
   "source": [
    "\n",
    "<details><summary>What is the baseline accuracy?</summary>\n",
    "    \n",
    "- If the value '0' occurs 87% of the time in our dataset, this means that if we predicted 'ham' all the time, we would have an accuracy of 87%.\n",
    "\n",
    "Our baseline accuracy is thus 87%.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the test data\n",
    "mb.score(X_test_tdm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ff7e8",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Not bad! We can now use the model to obtain predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = mb.predict(X_test_tdm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3012daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(mb, X_test_tdm, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94586989",
   "metadata": {},
   "source": [
    "## Hyperparameters, Gridsearch and Pipelining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ec6ae",
   "metadata": {},
   "source": [
    "Maybe we need to adjust our hyperparameters. But what values should be set for:\n",
    "\n",
    "`max_features`\n",
    "`min_df`\n",
    "`max_df`\n",
    "`ngram_range`\n",
    "\n",
    "that will give us the best prediction of whether a message is spam or ham? Looking at the plot of top occurring words, should we remove stopwords?\n",
    "\n",
    "We will need to use a gridsearch to search through the possible hyperparameters to obtain the best model.\n",
    "\n",
    "But first we should set up the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ee422",
   "metadata": {},
   "source": [
    "## Setting up the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0697dff",
   "metadata": {},
   "source": [
    "<details><summary>Is CountVectorizer an estimator or a transformer?</summary>\n",
    "    \n",
    "- A transformer.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c3cea",
   "metadata": {},
   "source": [
    "<details><summary>Why do we need a pipeline to GridSearch over our CountVectorizer hyperparameters?</summary>\n",
    "    \n",
    "- The CountVectorizer is a transformer.\n",
    "- Transformers have .fit() and .transform() methods, but cannot do .predict().\n",
    "- In order to GridSearch over hyperparameters, we need some way to score our model performance.\n",
    "- A pipeline stacks together one or more transformers with an estimator at the end. The estimator allows us to .predict() and get a score!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ba548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d135c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b105b2",
   "metadata": {},
   "source": [
    "## `GridSearchCV`\n",
    "---\n",
    "\n",
    "At this point, you could use your `pipeline` object as a model:\n",
    "\n",
    "```python\n",
    "# Estimate how your model will perform on unseen data\n",
    "cross_val_score(pipe, X_train, y_train, cv=3).mean() \n",
    "\n",
    "# Fit your model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Training score\n",
    "pipe.score(X_train, y_train)\n",
    "\n",
    "# Test score\n",
    "pipe.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "Since we want to tune over the `CountVectorizer`, we'll load our `pipeline` object into `GridSearchCV`.\n",
    "\n",
    "First set up the hyperparameter values for `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Stopwords: use 'english', or None\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__stop_words' : ['english', None],\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672f803",
   "metadata": {},
   "source": [
    "<details><summary>How many models are we fitting here?</summary>\n",
    "\n",
    "- 2 stop_words options\n",
    "- 4 max_features\n",
    "- 2 min_df\n",
    "- 2 max_df\n",
    "- 2 ngram_range\n",
    "- 5-fold CV\n",
    "- 2 * 4 * 2 * 2 * 2 * 5 = 320 models\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaee217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aed78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what were the best hyperparameters?\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60da62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a75ee6",
   "metadata": {},
   "source": [
    "<details><summary>Is accuracy the best score here?</summary>\n",
    "\n",
    "Since we are classifying whether or not a message is spam, I care more about minimizing false positives here (maximizing for specificity). I prefer for my important emails to go to my inbox (true negatives) and potentially have a few spam messages go to my inbox (false negative) than miss an important email that was incorrectly classified as spam (false positive). \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbfc41",
   "metadata": {},
   "source": [
    "### Review: Practice Using the `TfidfVectorizer`\n",
    "\n",
    "\n",
    "As you did above, instantiate the default `TfidfVectorizer`, then fit the spam and ham data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd112330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the transformer.\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89600e44",
   "metadata": {},
   "source": [
    "### Modeling Using the `TfidfVectorizer`\n",
    "\n",
    "Let's set up a pipeline using tf-idf and Multinomial Naive Bayes.\n",
    "\n",
    "<details><summary>What's the problem with this?</summary>\n",
    "\n",
    "- Technically, we are supposed to have positive integers to use Multinomial Naive Bayes. Tf-idf does not give us positive integers.\n",
    "- However, it will still work. Even the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) says \"The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\"\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f358e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with tf-idf vectorizer and multinomial naive bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adefc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# No stop words and english stop words\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f071eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearch to training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901035a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model on training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model on testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "\n",
    "\n",
    "# Save confusion matrix values\n",
    "\n",
    "# Calculate the specificity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize this\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f96983",
   "metadata": {},
   "source": [
    "Which model gives us a higher *specificity*?\n",
    "- `CountVectorizer`, or `TfidfVectorizer`?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
