{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Timeseries ARIMA Lab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Previously, we have attempted to fit the AAPL close price using a linear regression model based on the previous day's close and the current day's open price. Let's see if an ARIMA model can perform better.\n",
    "\n",
    "Let's set up the required imports and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will filter out a lot of future warnings from statsmodels\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_plots(y, lags=None):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "    plot_acf(y, lags=lags, ax=ax[0])\n",
    "    plot_pacf(y, lags=lags, ax=ax[1])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_plot(res):\n",
    "    resid_standard = (res - res.mean()) / res.std()\n",
    "    figure, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "\n",
    "    ax[0, 0].plot(res)\n",
    "    ax[0, 0].axhline(res.mean(), color='grey')\n",
    "    ax[0, 0].set_title('Residuals')\n",
    "\n",
    "    plot_acf(resid_standard, title='Correlogram', ax=ax[0, 1])\n",
    "    \n",
    "    sm.graphics.qqplot(res, line='45', fit=True, ax=ax[1, 0])\n",
    "  \n",
    "    ax[1, 0].set_title('Normal Q-Q')\n",
    "\n",
    "    x = np.linspace(res.min(), res.max(), 1000)\n",
    "    norm = stats.norm(loc=0, scale=res.std())\n",
    "    sns.distplot(res, ax=ax[1, 1], label='kde estimate')\n",
    "    ax[1, 1].plot(x, norm.pdf(x), label='normal distribution')\n",
    "    ax[1, 1].legend()\n",
    "    ax[1, 1].set_title('Distribution of Residuals')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the AAPL data\n",
    "\n",
    "************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/aapl_split_adjusted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values using head() and tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date as index\n",
    "df['Date'] = pd.to_datetime(df.Date).dt.to_period('D')\n",
    "df.sort_values(by='Date',inplace=True)\n",
    "df.set_index('Date',inplace=True)\n",
    "df.index.name = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Get Weekly Resampled Data\n",
    "\n",
    "The dates for the time series are not consistent (being days that the stock is traded) which makes the daily prediction problematic. Let's resample weekly to have a series of dates that is consistently spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the weekly mean close price\n",
    "close =df['Close'].resample('W',kind='timestamp').mean()\n",
    "close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Visualize the Time Series\n",
    "\n",
    "Make a plot of the weekly close values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.plot(lw=4, figsize=(12, 5))\n",
    "plt.title(\"Weekly Average Closing Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Checking for Stationarity\n",
    "\n",
    "**2.1 Plot the ACF and PACF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the autocorr_plots() function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the ACF and PACF tell you about whether the time series is stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Use the Augmented Dickey-Fuller statistical test**\n",
    "- H0: There is a unit root in a time series sample (indicating it is non-stationary)\n",
    "- H1: There is no unit root (so it is stationary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test = adfuller(close)\n",
    "print(f'p-value: {adf_test[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our p-value is ____________\n",
    "We reject/do not reject the null hypothesis and thus the series is stationary/nonstationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the training and test sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train based on data up to 20 weeks prior\n",
    "n = len(close)-20\n",
    "training = close[:n]\n",
    "test = close[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training and test head() and tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Determine ARIMA Parameters\n",
    "\n",
    "\n",
    "Now let's try to identify suitable values for the ARIMA model:\n",
    "- AR(p) \n",
    "- MA(q)\n",
    "- differencing (d)\n",
    "\n",
    "- p indicates how many prior time periods are taken into consideration for explained autocorrelation. Increasing p would increase the dependency on previous values further (longer lag).\n",
    "- q indicates how many prior time periods we are considering for observing sudden trend changes.\n",
    "- d indicates what difference we are anticipating to predict. We pick d in such a way that we produce a stationary time series (if we can)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing `d` parameter\n",
    "\n",
    "The `d` parameter specifies the amount of differencing required to make the series stationary. We can inspect the differenced values for stationarity using the ACF, PACF plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the differenced series, dropping the first row which will be NaN\n",
    "# If after plotting still not stationary, may need to difference again\n",
    "cdiff = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF and PACF on the differenced series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check by performing the ADF test on the differenced series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call adfuller to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our p-value is ____________\n",
    "We reject/do not reject the null hypothesis and thus the series is stationary/nonstationary\n",
    "\n",
    "Let's use `d=??`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose `p` and `q` parameters\n",
    "---\n",
    "<a id=\"how-to-choose-the-right-p-and-q-parameters\"></a>\n",
    "\n",
    "After having obtained the stationary time series, inspect the autocorrelation and partial autocorrelation plots.\n",
    "\n",
    "- Check the autocorrelations.\n",
    "- If all autocorrelations with a lag larger than q vanish, choose MA(q).\n",
    "- If there are autocorrelations at all lags (even if maybe very small), check for the partial autocorrelations.\n",
    "- If the partial autocorrelations for lags larger than p vanish, choose AR(p).\n",
    "- If both the ACF and PACF show a gradual decay, an ARMA model is likely appropriate as opposed to the AR or MA alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ACF and PACF again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the PACF plot to determine the autogression parameter, `p`.\n",
    "Use the ACF plot to determing the moving average parameter, `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with order=(p,d,q)\n",
    "p=\n",
    "d=\n",
    "q=\n",
    "model_ar=ARIMA(close, order=(p, d, q)).fit()\n",
    "print(model_ar.summary())\n",
    "print(model_ar.model.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecase values for the test set\n",
    "forecast_close = model_ar.forecast(len(test))\n",
    "\n",
    "# Store in a new dataframe\n",
    "weekly_df=pd.DataFrame()\n",
    "weekly_df['Close']=close\n",
    "weekly_df['forecast_close'] = [None]*len(training) + list(forecast_close)\n",
    "\n",
    "weekly_df[['Close','forecast_close']].plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our usual scores to compare true and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# get the metrics by comparing test and forecast_close values\n",
    "mae = \n",
    "mape = \n",
    "mse = \n",
    "rmse =\n",
    "\n",
    "print(f'mae - auto: {mae}')\n",
    "print(f'mape - auto: {mape}')\n",
    "print(f'rmse - auto: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals\n",
    "\n",
    "As in linear regression, we can judge the quality of our model by looking at our residuals. We would like that\n",
    "\n",
    "- there are no trends in the size of the residuals\n",
    " - plot the values of the residuals \n",
    "- the residuals are uncorrelated\n",
    " - plot the autocorrelations of the residuals (correlogram)\n",
    "- the residuals are normally distributed \n",
    " - compare to the standard normal distribution through quantile-quantile plot and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't include the first p residuals because they are based on the mean of the original series, since the forecasts are based on \n",
    "# the autoregression is based on lag p.\n",
    "# Check what the p value is\n",
    "res=model_ar.resid.values[p:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the residual_plot() function above to generate plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the plots and see check whether the residuals show any signs of other trends or patterns, correlation or non-normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "\n",
    "# Start predicting from which time period\n",
    "init_1 = 1\n",
    "# Stop predicting 10 time units into the future (10 weeks)\n",
    "end_1 = len(close)+10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "close.plot()\n",
    "plot_predict(model_ar,init_1,end_1,dynamic=False,plot_insample=True,ax=ax)\n",
    "ax.set_title('Non dynamic in-sample predictions and out-of-sample forecasts',fontsize=24)\n",
    "tick_dates=weekly_df.index.to_period('Q')\n",
    "plt.xticks(ticks=tick_dates, labels=tick_dates, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "337px",
    "left": "0px",
    "right": "615.295px",
    "top": "62px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
