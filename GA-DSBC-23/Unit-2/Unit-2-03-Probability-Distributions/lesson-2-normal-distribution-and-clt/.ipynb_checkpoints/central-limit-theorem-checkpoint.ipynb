{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# The Normal Distribution and the Central Limit Theorem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "### Core\n",
    "- Visualize the normal distribution\n",
    "- Understand the uses of the 68-95-99.7 rule\n",
    "- Visualize the 68-95-99.7 rule\n",
    "- Apply z-scoring to data\n",
    "\n",
    "### Target\n",
    "- Apply the Central Limit Theorem\n",
    "    - Create random samples from a data set\n",
    "    - Visualize the CLT by plotting the distribution of means obtained from different samples\n",
    "\n",
    "### Stretch\n",
    "- Use a quantile-quantile plot to compare a given distribution to the standard normal distribution\n",
    "- Understand the limitations of the central limit theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Lesson Guide<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Objectives\" data-toc-modified-id=\"Learning-Objectives-1\">Learning Objectives</a></span><ul class=\"toc-item\"><li><span><a href=\"#Core\" data-toc-modified-id=\"Core-1.1\">Core</a></span></li><li><span><a href=\"#Target\" data-toc-modified-id=\"Target-1.2\">Target</a></span></li><li><span><a href=\"#Stretch\" data-toc-modified-id=\"Stretch-1.3\">Stretch</a></span></li></ul></li><li><span><a href=\"#Sample-statistics-and-parameters\" data-toc-modified-id=\"Sample-statistics-and-parameters-2\">Sample statistics and parameters</a></span></li><li><span><a href=\"#The-Normal-distribution\" data-toc-modified-id=\"The-Normal-distribution-3\">The Normal distribution</a></span></li><li><span><a href=\"#The-68-95-99.7-Rule\" data-toc-modified-id=\"The-68-95-99.7-Rule-4\">The 68-95-99.7 Rule</a></span></li><li><span><a href=\"#The-z-score\" data-toc-modified-id=\"The-z-score-5\">The z-score</a></span></li><li><span><a href=\"#The-Central-Limit-Theorem\" data-toc-modified-id=\"The-Central-Limit-Theorem-6\">The Central Limit Theorem</a></span></li><li><span><a href=\"#Visualizing-the-CLT:-bikeshare-data\" data-toc-modified-id=\"Visualizing-the-CLT:-bikeshare-data-7\">Visualizing the CLT: bikeshare data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-in-the-data-and-extract-several-variables\" data-toc-modified-id=\"Load-in-the-data-and-extract-several-variables-7.1\">Load in the data and extract several variables</a></span></li><li><span><a href=\"#Create-a-function-for-plotting-the-distribution-of-a-variable\" data-toc-modified-id=\"Create-a-function-for-plotting-the-distribution-of-a-variable-7.2\">Create a function for plotting the distribution of a variable</a></span></li><li><span><a href=\"#Write-a-function-that-will-take-a-random-sample-of-given-size-$n$-of-any-of-the-variables-above-a-1000-times,-calculate-the-means-of-the-samples,-and-return-the-sample-means-as-a-new-list.\" data-toc-modified-id=\"Write-a-function-that-will-take-a-random-sample-of-given-size-$n$-of-any-of-the-variables-above-a-1000-times,-calculate-the-means-of-the-samples,-and-return-the-sample-means-as-a-new-list.-7.3\">Write a function that will take a random sample of given size $n$ of any of the variables above a 1000 times, calculate the means of the samples, and return the sample means as a new list.</a></span></li><li><span><a href=\"#Plot-the-sample-means-using-the-distribution-plotter-function.\" data-toc-modified-id=\"Plot-the-sample-means-using-the-distribution-plotter-function.-7.4\">Plot the sample means using the distribution plotter function.</a></span></li></ul></li><li><span><a href=\"#Independent-practice\" data-toc-modified-id=\"Independent-practice-8\">Independent practice</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-other-variables-from-the-dataset-to-test-the-central-limit-theorem.-Vary-$n$-and-$k$-until-you-get-a-sufficiently-normal-distribution-of-the-sample-means.\" data-toc-modified-id=\"Use-other-variables-from-the-dataset-to-test-the-central-limit-theorem.-Vary-$n$-and-$k$-until-you-get-a-sufficiently-normal-distribution-of-the-sample-means.-8.1\">Use other variables from the dataset to test the central limit theorem. Vary $n$ and $k$ until you get a sufficiently normal distribution of the sample means.</a></span></li></ul></li><li><span><a href=\"#Additional-resources\" data-toc-modified-id=\"Additional-resources-9\">Additional resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample statistics and parameters\n",
    "\n",
    "---\n",
    "\n",
    "Recall that we use sample statistics to estimate population parameters. Our goal is to calculate sample statistics and then rely on properties of a random sample (and perhaps additional assumptions) to make inferences that we can generalize to the larger population of interest.\n",
    "\n",
    "Below is a table comparing some example sample statistics and population parameters:\n",
    "\n",
    "Metric  | Statistic         | Parameter \n",
    "-------- | ------------------ | ------------------ \n",
    "mean   | $$\\bar{x} = \\frac{\\sum x}{n}$$ | $$ \\mu = \\frac{\\sum x}{N} $$      \n",
    "standard deviation   | $$ s = \\sqrt{\\frac{\\sum_i (x_i - \\bar{x})^2}{n-1}} $$ | $$ \\sigma = \\sqrt{\\frac{\\sum_i (x_i - \\mu)^2}{N} } $$\n",
    "correlation   | $$ r = \\frac{\\hat{Cov}(X, Y)}{s_X s_Y} $$ | $$ \\rho = \\frac{Cov(X, Y)}{\\sigma_X \\sigma_Y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Normal distribution\n",
    "\n",
    "---\n",
    "\n",
    "The normal distribution is arguably the most commonly used distribution in all of statistics. **Normality** is an assumption that underlies many statistical tests and serves as a convenient model for the distribution of many (but not all!) variables.\n",
    "\n",
    "The normal distribution relies on two parameters: \n",
    "- The population mean\n",
    "- The population standard deviation. \n",
    "\n",
    "If a variable follows a Normal distribution exactly, its mean, median, and mode will all be equal.\n",
    "\n",
    "**Example: Intelligence Quotient**\n",
    "\n",
    "Intelligence Quotient (IQ) follows a Normal distribution by design. IQ is Normally distributed with a mean of 100 and a standard deviation of 15. You might see this specified like:\n",
    "- IQ ~ Normal(100,15) \n",
    "- or IQ ~ N(100,15)\n",
    "\n",
    "**We can plot the Normal distribution N(100, 15) using `scipy`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate points on the x axis:\n",
    "xpoints = np.linspace(40, 160, 500)\n",
    "\n",
    "# Use stats.norm.pdf to get values on the probability density function for the Normal distribution\n",
    "ypoints = stats.norm.pdf(xpoints, 100, 15)\n",
    "\n",
    "# initialize a matplotlib \"figure\":\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "# Plot the lines using matplotlib's plot function:\n",
    "ax.plot(xpoints, ypoints, linewidth=3, color='darkred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The 68-95-99.7 Rule\n",
    "\n",
    "---\n",
    "\n",
    "It is often beneficial to identify how extreme (or far away from the expected value) a particular observation is within the context of a distribution. \n",
    "\n",
    "For example, an extreme stock price might indicate a major shift in the market. This might inform whether we choose to buy or sell. Or, an extreme drop in air pressure might indicate a significant weather event, necessitating a reaction from the National Weather Service. Quantifying just how extreme a particular observation is from the expected value (a.k.a., population mean) may indicate a particular action we should take.\n",
    "\n",
    "It is possible to show that, for a Normal distribution:\n",
    "- 68% of observations from a population will fall within $\\pm 1$ standard deviation of the population mean.\n",
    "- 95% of observations from a population will fall within $\\pm 2$ standard deviations of the population mean.\n",
    "- 99.7% of observations from a population will fall within $\\pm 3$ standard deviations of the population mean.\n",
    "\n",
    "**Check:** What percentage of individuals have an IQ between 85 and 115?\n",
    "\n",
    "**Check:** What percentage of individuals have an IQ above 100?\n",
    "\n",
    "**Check:** What percentage of individuals have an IQ between 85 and 130?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Below is a visual representation of the 68-95-99.7 rule on the IQ distribution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Set mean and standard deviation\n",
    "mu, sigma = 100, 15\n",
    "\n",
    "#Here is a set of points\n",
    "xpoints = np.random.normal(mu, sigma, 50000)\n",
    "\n",
    "avg = np.mean(xpoints)\n",
    "std = np.std(xpoints)\n",
    "\n",
    "#check your values\n",
    "print((avg,std))\n",
    "\n",
    "#Define variables for 1,2,3 sigma\n",
    "std1 = avg + std\n",
    "std1_neg = avg - std\n",
    "std2 = avg + 2*std\n",
    "std2_neg = avg - 2*std\n",
    "std3 = avg + 3*std\n",
    "std3_neg = avg - 3*std\n",
    "\n",
    "#Start Figure\n",
    "#---------------------------------------\n",
    "# Initialize a matplotlib \"figure\"\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "# 68%:\n",
    "ax.axvline(std1_neg, ls='dashed', lw=3, color='#333333', alpha=0.7, label='1 $\\sigma$')\n",
    "ax.axvline(std1, ls='dashed', lw=3, color='#333333', alpha=0.7)\n",
    "\n",
    "# 95%\n",
    "ax.axvline(std2_neg, ls='dashed', lw=3, color='#666666', alpha=0.7, label='2 $\\sigma$')\n",
    "ax.axvline(std2, ls='dashed', lw=3, color='#666666', alpha=0.7)\n",
    "\n",
    "# 99.7%\n",
    "ax.axvline(std3, ls='dashed', lw=3, color='#999999', alpha=0.7,label='3 $\\sigma$')\n",
    "ax.axvline(std3_neg, ls='dashed', lw=3, color='#999999', alpha=0.7)\n",
    "\n",
    "# plot the lines using matplotlib's hist function:\n",
    "ax.hist(xpoints,density=True, bins=100)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The z-score\n",
    "---\n",
    "\n",
    "While it's nice to have this 68-95-99.7 rule, we can get more specific. \n",
    "\n",
    "**The z-score of an observation quantifies how many standard deviations the observation is away from the population mean:**\n",
    "\n",
    "$$ z_i = \\frac{x_i - \\text{population mean of x}}{\\text{standard deviation of x}} $$\n",
    "\n",
    "If we have $X \\sim N(\\mu, \\sigma)$, with the random variable $X$ specified by a normal distribution with mean $\\mu$ and standard deviation $\\sigma$, we can specify the z-distribution as  $Z \\sim N(0,1)$. \n",
    "\n",
    "We call $Z$ the **standard normal distribution** because it has a mean of 0 and standard deviation of 1.\n",
    "\n",
    "The `scipy.stats.zscore` function will convert a vector of values to their respective z-scores.\n",
    "\n",
    "**Calculate the z-scores for a simple vector of values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "values = np.array([2,3,4,5,6])\n",
    "\n",
    "stats.zscore(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "**Check:** Describe how the `scipy.stats.zscore` function converts the vector of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "**Check:** If $X$ is not normal, but we calculate $Z$ by standardizing $X$ using the mean and standard deviation of $X$ as above, is Z ~ N(0,1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Normality underlies many of the inferential techniques that we will use in this course. That the normal distribution is of such importance is related to the central limit theorem.\n",
    "\n",
    "Consider the random variable $X$. We can take a sample from this population of size $n$ and find the mean of that sample. Let's call this sample mean $x_1$. We can take another sample from this population, also of size $n$, and find the mean of that sample. Let's call this sample mean $x_2$. We can do this over and over until we've calculated the mean of every possible sample of size $n$. If we plotted every sample mean on a histogram, we would get another distribution called \"the sampling distribution of $\\bar{X}$.\"\n",
    "\n",
    "**This distribution, the sampling distribution of $\\bar{X}$, is  normally distributed even if the distribution of $X$ is not.** (That is, unless some necessary conditions are violated).\n",
    "\n",
    "We can formally define [the central limit theorem](http://homepages.math.uic.edu/~bpower6/stat101/Sampling%20Distributions.pdf) in the following way:\n",
    "\n",
    "> In probability theory, the central limit theorem (CLT) states that, when independent random variables are added, their sum tends toward a normal distribution (commonly known as a bell curve), even if the original variables themselves are not normally distributed. In more precise terms, given certain conditions, the arithmetic mean of a sufficiently large number of iterates of independent random variables — each with a well-defined (finite) expected value and finite variance — will be approximately normally distributed, regardless of the underlying distribution.\n",
    "\n",
    "Some properties that arise from the central limit theorem include:\n",
    "\n",
    "> If $X \\sim N(\\mu,\\sigma)$, then $\\bar{X}$ is exactly $N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$.\n",
    "\n",
    "> If $X$ is not normally distributed, then $\\bar{X}$ is approximately $N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$ if the sample size $n$ is at least 30. As $n$ increases, $\\bar{X}$ becomes asymptotically normally distributed.\n",
    "\n",
    "> If $\\bar{X}$ is normally distributed, then we can use inferential methods that rely on our sample mean, $\\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing the CLT: bikeshare data\n",
    "\n",
    "---\n",
    "\n",
    "Below is the path to a `.csv` with a variety of data on bikesharing. Many of the variables measured in the data set are far from normally distributed. We will show that, despite this fact, the distribution of sample means for these variables will be asymptotically normally distributed, as proven by the CLT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load in the data and extract several variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('datasets//bikeshare.csv')\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data.hist(figsize=(12,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a function for plotting the distribution of a variable\n",
    "\n",
    "Apply this function to several variables. Are these variables normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def dist_plotter(sample,bins=50,kde=False):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.histplot(sample, bins=bins, kde=kde)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# apply the plotter to the some variables, try others \n",
    "dist_plotter(data.temp)\n",
    "dist_plotter(data.casual)\n",
    "dist_plotter(data.season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's write a function that will take a random sample of given size $n$ of any of the variables above a 1000 times, calculate the means of the samples, and return the sample means as a new list.\n",
    "\n",
    "*Hint: you can use `numpy`'s `np.random.choice` to perform your sampling.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sampler(population, n=30, k=1000):\n",
    "    'Takes k random samples of size n and returns a list of all the sample means'\n",
    "    sample_means = []\n",
    "    for i in range(k):\n",
    "        sample = np.random.choice(population, size=n, replace=True)\n",
    "        sample_means.append(np.mean(sample))\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot the sample means using the distribution plotter function.\n",
    "Is the distribution of sample means approximately normally distributed? What happens if you increase the number of sample means to 10,000? 100,000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n = 30\n",
    "k = 1000\n",
    "means = sampler(data.temp,n=n,k=k)\n",
    "dist_plotter(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n = 30\n",
    "k = 10000\n",
    "means = sampler(data.temp,n=n,k=k)\n",
    "dist_plotter(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n = 30\n",
    "k = 100000\n",
    "means = sampler(data.temp,n=n,k=k)\n",
    "dist_plotter(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That looks now reasonably like a normal distribution, but how good we got is difficult to judge by pure eye. For a better illustration we can use a **quantile-quantile plot**. It plots the quantile boundaries of a given (standardized) distribution versus the quantile boundaries of the standard normal distribution. If the given data were normally distributed, we would see a straight line passing through the origin with slope one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install statsmodels --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(np.array(means),line='45',fit=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent practice\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use other variables from the dataset to test the central limit theorem using the `sampler` function. Vary $n$ and $k$ until you get a sufficiently normal distribution of the sample means.\n",
    "\n",
    "Try:\n",
    "1) season column\n",
    "2) casual column\n",
    "3) holiday column\n",
    "\n",
    "Generate the qqplots to check the normality.\n",
    "\n",
    "Warning: The more skewed the distribution, the more you will have to increase both $n$ and $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional resources\n",
    "---\n",
    "\n",
    "http://blog.vctr.me/posts/central-limit-theorem.html\n",
    "\n",
    "http://www.usablestats.com/lessons/central_limit\n",
    "\n",
    "http://blog.minitab.com/blog/michelle-paret/explaining-the-central-limit-theorem-with-bunnies-and-dragons-v2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {
    "height": "90px",
    "width": "242px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
