{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Frequentist Hypothesis Testing: t-tests and p-values\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "### Core\n",
    "- Understand the fundamental concepts of frequentist hypothesis testing\n",
    "- Understand the difference between the null and alternative hypothesis\n",
    "- Understand the t-statistic, p-value, and t-test\n",
    "- Calculate the t-statistic and p-value by hand\n",
    "\n",
    "### Target\n",
    "- Visually represent the t-test and p-value using the t-distribution\n",
    "\n",
    "### Stretch\n",
    "- Understand how the t-test and frequentist hypothesis testing relate to the number of observations, the means and the standard deviations of each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Frequentist hypothesis testing: a drug experiment example](#frequentist-hypothesis-testing)\n",
    "- [The null hypothesis](#null-hypothesis)\n",
    "- [The alternative hypothesis](#alternative-hypothesis)\n",
    "- [Introduction to the t-test](#t-tests)\n",
    "- [The likelihood of the data given the null hypothesis](#likelihood-data)\n",
    "- [Calculating the t-statistic](#t-statistic)\n",
    "- [Visualizing the t-statistic](#visualizing-t-statistic)\n",
    "- [The p-value](#p-value)\n",
    "- [Visualizing the p-value](#visualize-p-value)\n",
    "- [An alternative view: signal and noise](#signal-noise)\n",
    "- [Additional resources](#additional-resources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='frequentist-hypothesis-testing'></a>\n",
    "\n",
    "### Hypothesis testing using Frequentist methods: a drug efficacy experiment\n",
    "\n",
    "---\n",
    "\n",
    "Frequentist methods lend themselves well to the concepts of experimental design. For example, say we are testing the efficacy of a new drug:\n",
    "\n",
    "- We randomly select 50 people to be in the placebo control condition and 50 people to receive the treatment.\n",
    "- We know our sample is selected from the broader, unknown population pool.\n",
    "- We can imagine that in a hypothetical parallel world we could have ended up with a different random sample of subjects from the population pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='null-hypothesis'></a>\n",
    "\n",
    "### The \"null hypothesis\"\n",
    "\n",
    "---\n",
    "\n",
    "The **null hypothesis** is a fundamental concept of Frequentist statistical tests. We typically denote the null hypothesis with **H0**. \n",
    "\n",
    "In our drug efficacy experiment example, we can define our null hypothesis to be that there is no difference between a subject taking a placebo and the treatment drug.\n",
    "\n",
    "In the context of experiments, we often talk about the \"control\" group and the \"experimental\" or \"treatment\" group. In our drug example, the control group is the group given the placebo and the treatment group is given the actual drug. We are interested in the average difference in blood pressure levels between the treatment and control groups.\n",
    "\n",
    "> **H0:** The mean difference between treatment and control groups is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alternative-hypothesis'></a>\n",
    "\n",
    "### The \"alternative hypothesis\"\n",
    "\n",
    "---\n",
    "\n",
    "The **alternative hypothesis** is the outcome of the experiment that we hope to show. In our example the alternative hypothesis is that there is in fact a mean difference in blood pressure between the treatment and control groups. \n",
    "\n",
    "> **H1:** The parameter of interest, our mean difference between treatment and control, is different than zero.\n",
    "\n",
    "**NOTE:** The null hypothesis and alternative hypothesis are concerned with the true values, or in other words the *parameter of the overall population*. Through the process of experimentation / hypothesis testing and statistical analysis of the results we will make an *inference* about this population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t-tests'></a>\n",
    "\n",
    "### Evaluating our experiment with a t-test and p-value\n",
    "\n",
    "---\n",
    "\n",
    "Say in our experiment we measure the following results:\n",
    "\n",
    "- The 50 subjects in the control group have an average systolic blood pressure of 121.38\n",
    "- The 50 subjects in the experimental / treatment group have an average systolic blood pressure of 111.56\n",
    "\n",
    "The difference between experimental and control groups is -9.82 points. But with 50 subjects in each group, how confident can we be that this measured difference is real? We can perform what is known as a **t-test** to evaluate this.\n",
    "\n",
    "First we will calculate a **t-statistic**. The t-statistic is a measure of the degree to which our groups differ standardized by the variance of our measurements.\n",
    "\n",
    "Secondly we will calculate a **p-value**. The p-value is a metric that indicates a probability that our measured difference was due to random chance in the sampling of subjects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can set up the experimental and control observations below as numpy arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = np.array([166, 165, 120,  94, 104, 166,  98,  85,  97,  87, 114, 100, 152,\n",
    "                    87, 152, 102,  82,  80,  84, 109,  98, 154, 135, 164, 137, 128,\n",
    "                    122, 146,  86, 146,  85, 101, 109, 105, 163, 136, 142, 144, 140,\n",
    "                    128, 126, 119, 121, 126, 169,  87,  97, 167,  89, 155])\n",
    "\n",
    "experimental = np.array([83, 100, 123,  75, 130,  77,  78,  87, 116, 116, 141,  93, 107,\n",
    "                         101, 142, 152, 130, 123, 122, 154, 119, 149, 106, 107, 108, 151,\n",
    "                         97,  95, 104, 141,  80, 110, 136, 134, 142, 135, 111,  83,  86,\n",
    "                         116,  86, 117,  87, 143, 104, 107,  86,  88, 124,  76])\n",
    "\n",
    "print(np.mean(control))\n",
    "print(np.mean(experimental))\n",
    "print(np.mean(experimental) - np.mean(control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(experimental, control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='likelihood-data'></a>\n",
    "\n",
    "### The likelihood of the data given the null hypothesis \n",
    "\n",
    "---\n",
    "\n",
    "For our experiment we will set up a null hypothesis and an alternative hypothesis:\n",
    "\n",
    "> **H0:** The difference in systolic blood pressure between the experimental and control groups is 0.\n",
    "\n",
    "> **H1:** The difference in systolic blood pressure between the experimental and control groups is not 0.\n",
    "\n",
    "Likewise, our measured difference is **-9.82**.\n",
    "\n",
    "As Frequentists we want to know:\n",
    "\n",
    "$$P(\\text{data}\\;|\\;\\text{mean difference})$$\n",
    "\n",
    "**What is the probability that we observed this data GIVEN a specified mean difference in blood pressure?**\n",
    "\n",
    "We obviously don't know the true mean difference in blood pressure resulting from the drug. The whole point of conducting the experiment is to evaluate the drug. **Instead we will assume that the true mean difference is zero: the null hypothesis H0 is assumed to be true:**\n",
    "\n",
    "$$P(\\text{data}\\;|\\;\\text{mean difference}=0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up sample mean difference as a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean difference between groups:\n",
    "mean_difference = np.mean(experimental) - np.mean(control)\n",
    "print(mean_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t-statistic'></a>\n",
    "\n",
    "### Calculating the t-statistic\n",
    "\n",
    "---\n",
    "\n",
    "When comparing two means the **t-statistic** is a classic metric for quantifying the difference between groups. In essence our t-statistic will be a standardized version of the difference between groups, where the standardization is adjusting for the variance in measurements.\n",
    "\n",
    "When comparing the difference between groups, we can calculate the two-sample t-statistic as\n",
    "\n",
    "$$t = \\frac{\\bar{x}_E - \\bar{x}_C}{\\sqrt {s^2 \\left(\\frac{1}{n_E} + \\frac{1}{n_C}\\right)}}$$\n",
    "\n",
    "where $\\bar{x}_E$ is the mean of our experimental group sample measurements and $\\bar{x}_C$ is the mean of our control group sample measurements.\n",
    "\n",
    "$n_E$ and $n_C$ are the number of observations in each group. \n",
    "\n",
    "The $s^2$ denotes our *sample variance*. In this version of the t-test we assume that the samples in the experimental and control groups are drawn from (approximately) normal distributions with the same population variance. There is another way to calculate the t-test where equal variance is not assumed, but in our case it is a reasonable assumption.\n",
    "\n",
    "The sample variance as an estimate of the population variance is calculated as the weighted average of the variances of each sample\n",
    "\n",
    "$$ s^2 = \\frac{\\sum_{i=1}^{n_E} (x_i - \\bar{x}_E)^2 + \\sum_{j=1}^{n_C} (x_j - \\bar{x}_C)^2}{ n_E + n_C -2} $$\n",
    "\n",
    "which combines the variance of the two group's measurements into a single, pooled metric. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the formula above calculate the t-statistic for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variance(sample_1, sample_2):\n",
    "    n_1 = len(sample_1)\n",
    "    n_2 = len(sample_2)\n",
    "    dev_1 = np.sum([(x - np.mean(sample_1))**2 for x in sample_1])\n",
    "    dev_2 = np.sum([(x - np.mean(sample_2))**2 for x in sample_2])\n",
    "    s_squared = float(dev_1 + dev_2) / (n_1 + n_2 - 2)\n",
    "    return s_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_statistic(experimental, control):\n",
    "    s_squared = sample_variance(experimental, control)\n",
    "    mean_1 = np.mean(experimental)\n",
    "    mean_2 = np.mean(control)\n",
    "    std = np.sqrt(s_squared * (1./len(experimental) + 1./len(control)))\n",
    "    return float(mean_1 - mean_2) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat = t_statistic(experimental, control)\n",
    "print('Manual t-statistic:', t_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify our calculation gives the same results as `scipy.stats.ttest_ind`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result = stats.ttest_ind(experimental, control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the formula for the t-test:\n",
    "- The numerator: the difference between the group means. Recall that our assumed mean difference is 0 (our null hypothesis).\n",
    "- The denominator: the square root of the pooled sample variance divided by the sample size. This is the standard error of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualizing-t-statistic'></a>\n",
    "\n",
    "### Visualizing the t-statistic\n",
    "\n",
    "---\n",
    "\n",
    "From the central limit theorem, we know that (with asymptotically infinite samples) the distribution of sample means drawn from a population is normal. As a consequence, [the ratio of the mean and standard error follows a student-t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution).\n",
    "\n",
    "We can plot the student-t distribution below. It is centered on zero, where a value of 0 corresponds to our null hypothesis. We can also plot a vertical line with our measured t-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points on the x axis between -4 and 4:\n",
    "xpoints = np.linspace(-4, 4, 500)\n",
    "\n",
    "# use stats.t.pdf to get values on the probability density function for the t-distribution\n",
    "# the second argument is the degrees of freedom: n1 + n2 - 2\n",
    "ypoints = stats.t.pdf(xpoints, (50+50-2), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a matplotlib \"figure\"\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "# get the current \"axis\" out of the figure\n",
    "ax = fig.gca()\n",
    "\n",
    "# plot the lines using matplotlib's plot function:\n",
    "ax.plot(xpoints, ypoints, linewidth=3, color='darkred')\n",
    "\n",
    "# plot a vertical line for our measured difference in rates t-statistic\n",
    "ax.axvline(t_stat, color='black', linestyle='--', lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p-value'></a>\n",
    "\n",
    "### The p-value\n",
    "\n",
    "---\n",
    "\n",
    "With the t-statistic, we are able to calculate the *statistical significance* of the test with a **p-value**. Statistical significance indicates our degree of confidence to infer a parameter about the overall population from a statistic calculated in our sample.\n",
    "\n",
    "Because of the unintuitive framing of Frequentist statistics, the p-value is often communicated and perceived incorrectly. It is important to remember that the p-value does **NOT** relate to the _probability of the parameter_. In frequentist statistics the parameter, such as the mean difference, is **fixed**. Probability is instead associated with the *data*.\n",
    "\n",
    "> **The p-value is the probability that, given the null hypothesis (H0) is true, we could have ended up with a statistic at least as extreme as the one measured from our random sample of data from the true population.**\n",
    "\n",
    "We have measured a difference in blood pressure of -9.82 between the experimental and control groups. We then calculated a t-statistic associated with this difference of -1.89. In our specific example:\n",
    "\n",
    "> The p-value is the probability that, given there is a 0.0 true difference in blood pressure between experimental and control conditions (no effect of the drug), we were able to calculate a t-statistic at least as extreme as -1.89 from a random sample of data from the true population. If the p-value is above a given threshold, the null hypothesis is accepted, if the p-value is below that threshold, the null hypothesis is rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize-p-value'></a>\n",
    "\n",
    "### Visualizing the p-value\n",
    "\n",
    "---\n",
    "\n",
    "Our null hypothesis states there is no difference between groups. A t-statistic for no difference between groups would be 0. \n",
    "\n",
    "Recall that our alternative hypothesis is that the difference between groups is *not* 0. This could mean the difference is greater than or less than zero â€“ we have not specified which one. This is known as a **2-tailed t-test** and is the one we are currently conducting. It is called \"2-tailed\" because when we say \"at least as extreme as ...\" we are thinking about the *magnitude* of our t-statistic.\n",
    "\n",
    "**Below we can plot the t-distribution again with our t-statistic of -1.89 as well as a t-statistic of 1.89 on the other side of the distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a matplotlib \"figure\"\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.plot(xpoints, ypoints, linewidth=3, color='darkred')\n",
    "\n",
    "ax.axvline(t_stat, color='black', linestyle='--', lw=5)\n",
    "ax.axvline(-t_stat, color='black', linestyle='--', lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our p-value corresponds to the area under the curve of the distribution where the magnitude of the t-statistic is greater than or equal to the one we measured (shown with dotted lines.)**\n",
    "\n",
    "The `stats.t.cdf` function is the cumulative distribution function and will calculate the area under the curve up to a specified t-statistic. \n",
    "\n",
    "**Calculate the area under the tails of the t-distribution beyond the dotted lines using the cdf function to verify that it is the same as the p-value calculated by scipy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tail = stats.t.cdf(t_stat, (50+50-2), 0, 1)\n",
    "upper_tail = 1. - stats.t.cdf(-t_stat, (50+50-2), 0, 1)\n",
    "p_value = lower_tail + upper_tail\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='signal-noise'></a>\n",
    "\n",
    "### An alternative view of the t-test: signal and noise\n",
    "\n",
    "---\n",
    "\n",
    "Another way to think about the t-statistic is in terms of the **signal to noise ratio** in our data.\n",
    "\n",
    "**The signal is our measured difference.** This is our measured mean difference between groups minus the hypothesized mean **H0**.\n",
    "\n",
    "**The noise is the variation in our data**, how much our measurements vary across the groups. The t-distribution also imposes an additional penalty for smaller sample sizes by \"fattening the tails\" of the distribution when the number of observations is small.\n",
    "\n",
    "Let's explore how variance, or _noise_, affects our ability to detect true differences. Below is a function that will generate blood pressure measurements for groups with a specified mean, standard deviation, and number of samples. The samples will be drawn from a normal distribution parameterized by the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_group(mean, std, n):\n",
    "    return np.random.normal(mean, std, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate two groups of 100 observations each. Group one has `mean=100` and `std=5`, group two has `mean=110` and `std=5`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "g1 = generate_group(100, 5, 100)\n",
    "g2 = generate_group(110, 5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the distributions of each group on the same plot with histograms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matplotlib figure and get the axis:\n",
    "# initialize a matplotlib figure\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# get the current axis out of the figure\n",
    "ax = fig.gca()\n",
    "\n",
    "# create a distribution plot with seaborn's distplot, passing in the axis and also returning it:\n",
    "# first plot group 1:\n",
    "sns.histplot(g1, bins=20, color='steelblue', ax=ax, kde=False, label='group 1',alpha=0.3)\n",
    "\n",
    "# create another distribution on the same axis for group 2:\n",
    "sns.histplot(g2, bins=20, color='darkred', ax=ax, kde=False, label='group 2',alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_These are randomly created groups, so expect your output to vary from your classmates_\n",
    "\n",
    "However, you should be able to see that the two groups are quite distinct from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use scipy to calculate the t-statistic and p-value for the difference in means between the two groups.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the p-valu \n",
    "print(stats.ttest_ind(g1, g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate two groups of 100 observations each again, but this time group one has `mean=100` and `std=50`, group two has `mean=110` and `std=50`.**\n",
    "\n",
    "By increasing the standard deviation of the distribution the observations are drawn from, we are sampling more variable measurements. If measurements are more variable this implies more *noise* in the measurements. Precise measurements will have low variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "g3 = generate_group(100, 50, 100)\n",
    "g4 = generate_group(110, 50, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the groups again and calculate the t-statistic and p-value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = fig.gca()\n",
    "\n",
    "sns.histplot(g3, bins=20, color='steelblue', ax=ax, kde=False, label='group 1',alpha=0.3)\n",
    "sns.histplot(g4, bins=20, color='darkred', ax=ax, kde=False, label='group 2',alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(stats.ttest_ind(g3, g4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the amount of noise, or variance in our observations, we have decreased the ability to infer a difference between groups despite the overall group populations having the same mean difference.\n",
    "\n",
    "**In statistical testing of experiments there are fundamental relationships between sample size, the magnitude of the difference (signal), the variability in our measurements (noise), and our degree of confidence in inferences about the overall population.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='additional-resources'></a>\n",
    "\n",
    "### Additional resources\n",
    "\n",
    "---\n",
    "\n",
    "[A gentle overview of the t-test procedure](http://blog.minitab.com/blog/statistics-and-quality-data-analysis/what-are-t-values-and-p-values-in-statistics)\n",
    "\n",
    "[Another overview of the t-test procedure](http://www.statsdirect.com/help/parametric_methods/utt.htm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
